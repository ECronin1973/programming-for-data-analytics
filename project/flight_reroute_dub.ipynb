{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae6fbf9",
   "metadata": {},
   "source": [
    "# Flight Rerouting Analysis at Dublin Airport\n",
    "\n",
    "This project investigates flight rerouting events at Dublin Airport and their relationship to local weather conditions. The analysis combines flight activity data with historical and forecast weather data from Met √âireann to identify trends, visualise reroute reasons, and project future rerouting probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037f7b5",
   "metadata": {},
   "source": [
    "## Setup Instructions - Import Libraries\n",
    "\n",
    "This notebook requires the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86305781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\eCron\\OneDrive\\Documents\\ATU_CourseWork\\Programming For Data Analytics\\programming-for-data-analytics\\big-project\n",
      "Data directory: C:\\Users\\eCron\\OneDrive\\Documents\\ATU_CourseWork\\Programming For Data Analytics\\programming-for-data-analytics\\big-project\\data\n",
      "Output directory: C:\\Users\\eCron\\OneDrive\\Documents\\ATU_CourseWork\\Programming For Data Analytics\\programming-for-data-analytics\\big-project\\outputs\n",
      "Model directory: C:\\Users\\eCron\\OneDrive\\Documents\\ATU_CourseWork\\Programming For Data Analytics\\programming-for-data-analytics\\big-project\\models\n",
      "Docs directory: C:\\Users\\eCron\\OneDrive\\Documents\\ATU_CourseWork\\Programming For Data Analytics\\programming-for-data-analytics\\big-project\\docs\n"
     ]
    }
   ],
   "source": [
    "# Setup: imports, paths and basic config\n",
    "import json  # for any config files\n",
    "from pathlib import Path  # for path management\n",
    "import numpy as np  # numerical operations\n",
    "import pandas as pd  # data manipulation\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "import seaborn as sns  # enhanced plotting\n",
    "import plotly.express as px  # interactive plotting\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score  # model validation\n",
    "from sklearn.linear_model import LogisticRegression  # example model\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # example model\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix  # model evaluation\n",
    "import joblib  # model persistence\n",
    "\n",
    "# Plotting style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Explicit project root: programming-for-data-analytics/project\n",
    "ROOT = Path.cwd().resolve()\n",
    "if ROOT.name != \"project\":\n",
    "    # climb up until we find project folder\n",
    "    for parent in ROOT.parents:\n",
    "        if parent.name == \"project\":\n",
    "            ROOT = parent\n",
    "            break\n",
    "\n",
    "# Define key directories inside project\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "OUTPUT_DIR = ROOT / \"outputs\"\n",
    "MODEL_DIR = ROOT / \"models\"\n",
    "DOCS_DIR = ROOT / \"docs\"\n",
    "\n",
    "# Ensure directories exist\n",
    "for path in [DATA_DIR, OUTPUT_DIR, MODEL_DIR, DOCS_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {ROOT}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")\n",
    "print(f\"Docs directory: {DOCS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468332e9",
   "metadata": {},
   "source": [
    "### Step 3 ‚Äì Utilise Helper Functions for Dublin Airport Data Processing\n",
    "\n",
    "This section defines a set of reusable helper functions that simplify common tasks in the project.  \n",
    "They are designed specifically to support the analysis of **Dublin Airport flight activity and weather data** by handling messy inputs and preparing clean datasets for exploration and modelling.\n",
    "\n",
    "The functions help with:\n",
    "\n",
    "- ‚úÖ Detecting and parsing inconsistent datetime formats in flight and weather logs  \n",
    "- ‚úÖ Standardising and cleaning temperature columns from Met √âireann datasets  \n",
    "- ‚úÖ Loading and preparing Dublin Airport daily weather data from local CSV files  \n",
    "- ‚úÖ Defining Irish seasonal boundaries for rerouting analysis (Winter, Spring, Summer, Autumn)  \n",
    "- ‚úÖ Filtering weather data for a custom date range to align with flight events  \n",
    "- ‚úÖ Validating user-provided date inputs for reproducible analysis  \n",
    "- ‚úÖ Detecting header rows in raw CSV files downloaded from dashboards  \n",
    "\n",
    "Each helper is **modular** ‚Äî it performs one clear task and can be reused across notebooks and scripts.  \n",
    "This improves readability, reduces duplication, and supports good programming practices for the final project.\n",
    "\n",
    "üìå *Tip: These helpers are written to be beginner-friendly, with comments explaining their purpose and logic. They make it easier to align flight activity with weather conditions when investigating rerouting events.*\n",
    "\n",
    "üìñ References:  \n",
    "- [Real Python ‚Äì Python Helper Functions](https://realpython.com/defining-your-own-python-function/)  \n",
    "- [GeeksforGeeks ‚Äì Python Helper Functions](https://www.geeksforgeeks.org/python-helper-functions/)  \n",
    "- [Wikipedia ‚Äì DRY Principle (Don't Repeat Yourself)](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607be6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Helper Functions for Dublin Airport Project\n",
    "# These functions help with parsing dates, cleaning weather data, handling temperature columns,\n",
    "# defining Irish seasons, preparing data ranges, and detecting CSV headers.\n",
    "# Keep them in one cell so they are easy to reuse across the notebook.\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# üìÖ Detect the most likely datetime format from sample strings\n",
    "def detect_datetime_format(samples, formats, dayfirst=True):\n",
    "    \"\"\"\n",
    "    Try each format and return the one that matches at least 70% of samples.\n",
    "    Helps ensure consistent parsing of date strings.\n",
    "    \"\"\"\n",
    "    for fmt in formats:\n",
    "        parsed = pd.to_datetime(samples, format=fmt, dayfirst=dayfirst, errors='coerce')\n",
    "        if parsed.notna().sum() >= max(1, int(len(samples) * 0.7)):\n",
    "            return fmt\n",
    "    return None\n",
    "\n",
    "# üìÖ Parse a datetime column using format detection or fallback\n",
    "def parse_datetime_column(df, date_col, candidate_formats=None, dayfirst=True):\n",
    "    \"\"\"\n",
    "    Parse a datetime column using known formats.\n",
    "    Falls back to flexible parsing if none match.\n",
    "    \"\"\"\n",
    "    if candidate_formats is None:\n",
    "        candidate_formats = [\n",
    "            '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M', '%d-%b-%Y %H:%M',\n",
    "            '%d/%m/%Y %H:%M:%S', '%d/%m/%Y %H:%M', '%d-%m-%Y %H:%M',\n",
    "            '%d %b %Y %H:%M', '%d %B %Y %H:%M',\n",
    "        ]\n",
    "\n",
    "    sample_vals = df[date_col].dropna().astype(str).head(80).tolist()\n",
    "    chosen_fmt = detect_datetime_format(sample_vals, candidate_formats, dayfirst=dayfirst)\n",
    "\n",
    "    if chosen_fmt:\n",
    "        print(f\"‚úÖ Detected datetime format: {chosen_fmt}\")\n",
    "        return pd.to_datetime(df[date_col], format=chosen_fmt, dayfirst=dayfirst, errors='coerce')\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No single format matched. Falling back to flexible parsing.\")\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore', message='Could not infer format')\n",
    "            return pd.to_datetime(df[date_col], dayfirst=dayfirst, errors='coerce')\n",
    "\n",
    "# üå°Ô∏è Ensure temperature column is numeric and named 'temp'\n",
    "def parse_temperature_column(df, col_name='temp'):\n",
    "    \"\"\"\n",
    "    Convert the temperature column to numeric and rename it to 'temp'.\n",
    "    If no exact match, look for any column containing 'temp'.\n",
    "    \"\"\"\n",
    "    if col_name not in df.columns:\n",
    "        col_name = next((c for c in df.columns if 'temp' in c.lower()), None)\n",
    "        if col_name is None:\n",
    "            raise KeyError(\"No temperature column found.\")\n",
    "    df['temp'] = pd.to_numeric(df[col_name], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# üìÇ Load cleaned weather data from local CSV\n",
    "def load_cleaned_weather_data(filepath=\"data/dublin_airport_daily.csv\"):\n",
    "    \"\"\"\n",
    "    Load weather dataset from CSV and strip spaces from column names.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath, low_memory=False)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "# üçÇ Define Irish seasonal boundaries for a given year\n",
    "def define_irish_seasons(year=2025):\n",
    "    \"\"\"\n",
    "    Return start and end dates for Irish meteorological seasons.\n",
    "    \"\"\"\n",
    "    data = [\n",
    "        (\"Winter\", pd.Timestamp(f\"{year-1}-12-01\"), pd.Timestamp(f\"{year}-02-28 23:59\")),\n",
    "        (\"Spring\", pd.Timestamp(f\"{year}-03-01\"), pd.Timestamp(f\"{year}-05-31 23:59\")),\n",
    "        (\"Summer\", pd.Timestamp(f\"{year}-06-01\"), pd.Timestamp(f\"{year}-08-31 23:59\")),\n",
    "        (\"Autumn\", pd.Timestamp(f\"{year}-09-01\"), pd.Timestamp(f\"{year}-11-30 23:59\")),\n",
    "    ]\n",
    "    return pd.DataFrame(data, columns=[\"season\", \"start\", \"end\"])\n",
    "\n",
    "# üìä Filter and prepare temperature data for a custom date range\n",
    "def prepare_temperature_data(df, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Filter weather data to a date range and add useful time features.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    if 'date' not in df.columns:\n",
    "        raise KeyError(\"Expected 'date' column not found.\")\n",
    "\n",
    "    # Try parsing with a common format, fallback to flexible parsing\n",
    "    try:\n",
    "        df['datetime'] = pd.to_datetime(df['date'], format='%d-%b-%Y %H:%M', errors='raise')\n",
    "    except Exception:\n",
    "        df['datetime'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "    df = df.dropna(subset=['datetime'])\n",
    "    mask = (df['datetime'] >= start_date) & (df['datetime'] <= end_date)\n",
    "    range_df = df.loc[mask].copy()\n",
    "\n",
    "    # Add date and hour columns for plotting\n",
    "    range_df['date'] = range_df['datetime'].dt.date\n",
    "    range_df['hour'] = range_df['datetime'].dt.strftime('%H:%M')\n",
    "\n",
    "    return range_df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "# üìÜ Convert user input strings into a validated date range\n",
    "def get_custom_range(start_str, end_str):\n",
    "    \"\"\"\n",
    "    Convert string inputs into datetime objects and validate order.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start = pd.to_datetime(start_str)\n",
    "        end = pd.to_datetime(end_str)\n",
    "        if start > end:\n",
    "            raise ValueError(\"Start date must be before end date.\")\n",
    "        return start, end\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Invalid date range: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# üîç Detect the header row in a CSV file\n",
    "def detect_header(lines):\n",
    "    \"\"\"\n",
    "    Detect the most likely header row in a CSV file.\n",
    "    Looks for lines starting with 'date' or 'station' and containing commas.\n",
    "    \"\"\"\n",
    "    for i, line in enumerate(lines):\n",
    "        line_lower = line.strip().lower()\n",
    "        if (line_lower.startswith(\"station\") or line_lower.startswith(\"date\")) and \",\" in line:\n",
    "            columns = line.split(\",\")\n",
    "            if len(columns) > 5:  # Header rows usually have multiple columns\n",
    "                return i\n",
    "    print(\"‚ö†Ô∏è Warning: header row not found. Defaulting to first line.\")\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ecf4c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Step 4 ‚Äì Download Dublin Airport Daily Data CSV and Detect Header Row\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# --- Define output path for cleaned CSV ---\n",
    "DATA_PATH = Path(\"data/dublin_airport_daily.csv\")\n",
    "\n",
    "# --- Download raw CSV from Met √âireann (Dublin Airport Daily Data) ---\n",
    "url = \"https://cli.fusio.net/cli/climate_data/webdata/dly532.csv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# ‚úÖ Check for successful response\n",
    "if response.status_code != 200:\n",
    "    raise RuntimeError(f\"‚ùå Failed to download data: HTTP {response.status_code}\")\n",
    "\n",
    "# --- Split response into lines ---\n",
    "lines = response.text.splitlines()\n",
    "\n",
    "# --- Detect header row using helper function ---\n",
    "header_index = detect_header(lines)\n",
    "\n",
    "# ‚úÖ Confirm detected header row\n",
    "print(f\"‚úÖ Header row detected at line {header_index}:\")\n",
    "print(lines[header_index])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
